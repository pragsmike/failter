# **Failter: Design Document**

**Version:** 3.0
**Audience:** Developers joining the project who need to understand its architecture, design principles, and how to contribute.

## 1. Overview & Philosophy

**Failter** is a command-line framework for systematically filtering text using Large Language Models (LLMs). Its primary purpose is to serve as an experimentation harness to compare the performance of different models and prompt engineering strategies for specific text transformation tasks.

The core philosophy is to treat **prompts as code**. Instead of implementing filtering logic in a traditional programming language, Failter defines transformations in natural language via prompt templates. This allows for rapid iteration on the logic itself. The framework then provides the necessary machinery to rigorously test, evaluate, and analyze the performance of these prompts across a wide range of variables.

## 2. Core Concepts

The system is built around two first-class data structures, defined as records:

*   **`Trial` Record:** The atomic unit of work. A single trial represents the plan to process one **input file** with one **prompt template** using one **LLM model**. After execution, this record is hydrated with performance metrics (`execution-time-ms`, `cost`) or an `error`.

*   **`Eval` Record:** The result of a qualitative assessment. It contains the `Trial` record it is assessing, along with a `grade` (A-F), a `rationale` from the judge LLM, the `method` of evaluation used, and the `judge-model` that performed the assessment.

*   **Experiment:** A collection of trials defined by a self-contained directory. An experiment holds all inputs, templates, models, and the on-disk artifacts generated by trial runs and evaluations.

## 3. System Architecture & Data Flow

Failter operates as a three-stage pipeline, orchestrated by the user via command-line subcommands. The key design principle is the flow of explicit data records (`Trial`, `Eval`) between these stages.

```
+------------+      +--------------------+      +----------------+      +-------------------+
| <exp_dir>/ |----->| failter experiment |----->|  Seq of Trial  |----->|  failter runner   |
+------------+      | (Orchestrator)     |      |    records     |      |    (Executor)     |
                    +--------------------+      +----------------+      +-------------------+
                                                                                |
                                                                                V
                                                                    +----------------------+
                                                                    | <exp_dir>/results/   |
                                                                    |  (Hydrated .md files)|
                                                                    +----------------------+
                                                                                |
+------------+      +------------------+      +----------------+                |
| <exp_dir>/ |----->| failter evaluate |----->|  Seq of Eval   |----------------+
+------------+      |    (Producer)    |      |    records     |
                    +------------------+      +----------------+
                                                      |
                                                      V
+------------+      +-----------------+      +-----------------+
| <exp_dir>/ |----->| failter report  |----->| report.md,      |
+------------+      |   (Consumer)    |      | report.csv      |
                    +-----------------+      +-----------------+
```

## 4. Key Design Principles

*   **Filesystem as Database:** The entire state of an experiment—its inputs, configuration, results, and evaluations—is contained within its directory. This makes experiments highly portable, easily browsable, and naturally compatible with version control. The `failter.exp-paths` namespace provides the formal "API" to this database.

*   **First-Class Data Records:** The system avoids passing around ad-hoc maps. The `Trial` and `Eval` records provide a clear, self-documenting structure for the data that flows between the major components of the application.

*   **Centralized Configuration:** All application configuration (API endpoints, default models, timeouts, etc.) is stored in the `failter.config` namespace, providing a single source of truth.

## 5. Ground Truth Evaluation

The framework includes a sophisticated, optional evaluation method that compares a model's output against a human-verified "perfect" example.

*   **Directory Convention:** A new, optional directory named `ground_truth/` is recognized at the root of an experiment. For any input `inputs/doc.md`, its corresponding ground truth file must be at `ground_truth/doc.md`.
*   **Context Switching:** When the `evaluate` command runs, it checks for the existence of a ground truth file for each trial.
    *   **If it exists:** A special four-part prompt is used, asking the judge LLM to compare the `GENERATED_OUTPUT` to the `GROUND_TRUTH_EXAMPLE`. The resulting `.eval` artifact explicitly records the method as `ground-truth`.
    *   **If it does not exist:** The system gracefully falls back to the standard three-part prompt, and the method is recorded as `rules-based`.
*   **Transparent Reporting:** The final report includes an `Eval Methods` column, ensuring that scores derived from different methodologies are not incorrectly compared.

## 6. Codebase Tour (Module Breakdown)

The codebase is organized into distinct namespaces with clear responsibilities.

*   `failter.core`: Main application entry point and command-line dispatcher. Uses `clojure.tools.cli` for robust parsing of subcommands and options, then delegates to the appropriate namespace.
*   `failter.config`: A single map containing all application configuration.
*   `failter.util`: A utility belt for small, generic, pure helper functions (e.g., file readers, YAML block parser).
*   `failter.exp-paths`: The definitive API for the experiment's directory structure. All path construction and file discovery logic is centralized here.

*   `failter.trial`: Defines the `Trial` record and its constructors (`new-trial`, `from-file`).
*   `failter.eval`: Defines the `Eval` record and its I/O helpers (`read-eval`, `write-eval`, `read-all-evals`). This namespace is the primary interface between the evaluator and the reporter.

*   `failter.experiment`: **Produces** a sequence of `Trial` records by creating all combinations of inputs, templates, and models.
*   `failter.runner`: **Consumes** a `Trial` record and executes it, writing the hydrated result file to disk.
*   `failter.evaluator`: **Consumes** completed `Trial` records (by reading them via `trial/from-file`) and **produces** `Eval` records by calling the judge LLM and writing the results with `eval/write-eval`.
*   `failter.reporter`: A pure **consumer** of `Eval` records. It calls `eval/read-all-evals` to get a clean sequence of data, then performs transformations and formatting to generate the final reports.

*   `failter.llm-interface` / `failter.frontmatter`: Lower-level utility namespaces for interacting with the LLM proxy and handling file frontmatter, respectively.

## 7. How to Extend the System

*   **To Add a New Reporter Format (e.g., JSON):**
    1.  In `reporter.clj`, create a new function `(format-as-json [summaries])`.
    2.  `generate-report` already has the `summaries` data structure. Call your new function and `spit` the result to `report.json`. No other modules are affected.

*   **To Change the `results/` Directory Structure:**
    1.  Modify the logic inside the `output-path-for-trial` function in `failter.exp-paths.clj`.
    2.  All other parts of the system will automatically adhere to the new structure, as they rely on this single function.

*   **To Add a New Evaluation Method:**
    1.  Add a new prompt path to `failter.config`.
    2.  Update the `build-judge-prompt` logic in `evaluator.clj` to select your new prompt based on data in the `context` map.
